{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os as os\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import copy\n",
    "import h5py\n",
    "import keras as keras\n",
    "from keras.layers import Input, merge\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.core import Dropout, Activation\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "import time\n",
    "sys.path.append(os.path.abspath('squeezeNet_classification1'))\n",
    "from squeezenet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fishTypes : ALB\n",
      "fishTypes : BET\n",
      "fishTypes : DOL\n",
      "fishTypes : LAG\n",
      "fishTypes : OTHER\n",
      "fishTypes : SHARK\n",
      "fishTypes : YFT\n",
      "number of score maps :  3312\n"
     ]
    }
   ],
   "source": [
    "## this code creates the ground truth images, and the corresponding heatMaps, aquired by hand labelling\n",
    "## of the training data. \n",
    "## the input to my net will be an image of 720x1080x3\n",
    "## the output is a heatMap of 16x27\n",
    "\n",
    "projectPath = 'C:\\\\Users\\\\David\\\\Desktop\\\\GitFolder\\\\project1'\n",
    "dataPath = 'C:\\\\Users\\\\David\\\\Desktop\\\\Fish\\\\train\\\\train'\n",
    "scorePath = os.path.join('C:\\\\Users\\\\David\\\\Desktop\\\\Fish', 'train', 'binaryScoreMaps')\n",
    "\n",
    "# run through binaryScoreMap folders and count how many are there\n",
    "fishTypes = os.listdir(scorePath)\n",
    "numOfImages = 0\n",
    "for fishIdx in np.arange(len(fishTypes)):\n",
    "    print \"fishTypes : \" + fishTypes[fishIdx]\n",
    "    fishPath = os.path.join(scorePath, fishTypes[fishIdx])\n",
    "    # filter all non jpg files\\folders\n",
    "    imageNames = [fn for fn in os.listdir(fishPath) if fn.endswith(\"jpg\")]\n",
    "    numOfImages = numOfImages + len(imageNames)\n",
    "    \n",
    "print 'number of score maps : ', numOfImages\n",
    "h_score = 16 #720\n",
    "h_img = 720\n",
    "w_score = 27 #1080\n",
    "w_img = 1080\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fishType number : 0/7\n",
      "fishType number : 1/7\n",
      "fishType number : 2/7\n",
      "fishType number : 3/7\n",
      "fishType number : 4/7\n",
      "fishType number : 5/7\n",
      "fishType number : 6/7\n"
     ]
    }
   ],
   "source": [
    "# create an array of all scoreMaps & all images\n",
    "# scoreMaps are 4D and now contains also the number of classes\n",
    "scoreMaps = np.zeros((len(fishTypes)+1, h_score, w_score, numOfImages)) # '+1' is to add a 'noFish' class\n",
    "images = np.zeros((numOfImages,3, h_img, w_img), dtype=np.float32)\n",
    "theNumberOne = np.ones((1,1,1,1))\n",
    "\n",
    "# run through the data, and save all of it within an array\n",
    "counter = 0\n",
    "for fishIdx in np.arange(len(fishTypes)):\n",
    "    fishPath = os.path.join(scorePath, fishTypes[fishIdx])\n",
    "    # filter all non jpg files\\folders\n",
    "    scoreMapNames = [fn for fn in os.listdir(fishPath) if fn.endswith(\"jpg\")]\n",
    "    # run through the images and perform 2 things:\n",
    "    # 1. resize the score images to be of size h_score x w_score\n",
    "    # 2. perform all required data manipulation on the images themselfs..\n",
    "    # save all...\n",
    "    print 'fishType number : ' + np.str(fishIdx) + '/' + np.str(len(fishTypes))\n",
    "    for imageIdx in np.arange(len(scoreMapNames)):\n",
    "        # print the number of image\n",
    "        #print 'image number : ' + np.str(counter) + '/' + np.str(numOfImages)\n",
    "        # everything about the image\n",
    "        imagePath = os.path.join(dataPath, fishTypes[fishIdx], scoreMapNames[imageIdx])\n",
    "        img = misc.imread(imagePath).astype(np.float32)\n",
    "        img = misc.imresize(img, (720, 1080)).astype(np.float32)\n",
    "        #plt.imshow(img)        \n",
    "        aux = copy.copy(img)\n",
    "        img[:, :, 0] = aux[:, :, 2]\n",
    "        img[:, :, 2] = aux[:, :, 0]\n",
    "        # Remove train image mean\n",
    "        img[:, :, 0] -= 104.006\n",
    "        img[:, :, 1] -= 116.669\n",
    "        img[:, :, 2] -= 122.679\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        images[counter,:,:,:] = img\n",
    "        \n",
    "        #everything about the scoreMap\n",
    "        scoreMapPath = os.path.join(fishPath, scoreMapNames[imageIdx])\n",
    "        scoreMap = misc.imread(scoreMapPath, mode='L').astype(np.float32)\n",
    "        scoreMap = misc.imresize(scoreMap, (h_score,w_score)).astype(np.bool)\n",
    "        scoreMaps[fishIdx,:,:,counter] = scoreMap\n",
    "        scoreMaps[len(fishTypes),:,:,counter] = theNumberOne-scoreMap\n",
    "        counter += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready to start training...\n"
     ]
    }
   ],
   "source": [
    "# try training the network\n",
    "model = get_squeezenet(len(fishTypes)+1,720,1080, dim_ordering='th')\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
    "model.load_weights(os.path.abspath('squeezeNet_classification1/model/squeezenet_weights_th_dim_ordering_th_kernels.h5'), by_name=True)\n",
    "\n",
    "transposedScoreMaps = np.transpose(scoreMaps, (3, 0, 1,2))\n",
    "print 'ready to start training...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2980 samples, validate on 332 samples\n",
      "Epoch 1/4\n",
      "  40/2980 [..............................] - ETA: 5190s - loss: 12.6740"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-0cf4c794e006>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpartialPath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"weights-improvement-{epoch:02d}-{acc:.2f}.hdf5\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\Users\\David\\Desktop\\Fish\\classification'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpartialPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave_weights_only\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'max'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransposedScoreMaps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m#model.save('C:\\Users\\David\\Desktop\\Fish\\kerasModel\\SecondModel' + np.str(epochNum) + '.h5')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\David\\Anaconda2\\lib\\site-packages\\keras\\engine\\training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[0;32m   1190\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1192\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\David\\Anaconda2\\lib\\site-packages\\keras\\engine\\training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m    879\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m                         \u001b[1;31m# do not slice the training phase flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 881\u001b[1;33m                         \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    882\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\David\\Anaconda2\\lib\\site-packages\\keras\\engine\\training.pyc\u001b[0m in \u001b[0;36mslice_X\u001b[1;34m(X, start, stop)\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "partialPath=\"weights-improvement-{epoch:02d}-{acc:.2f}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(os.path.join('C:\\Users\\David\\Desktop\\Fish\\classification',partialPath), monitor='acc', verbose=1, save_best_only=True,save_weights_only = False, mode='max')\n",
    "model.fit(x=images, y=transposedScoreMaps, batch_size=10, nb_epoch=4, verbose=1, callbacks=[checkpoint], validation_split=0.1, shuffle=True, class_weight=np.array([1.5, 0.5]), sample_weight=None, initial_epoch=0)\n",
    "    #model.save('C:\\Users\\David\\Desktop\\Fish\\kerasModel\\SecondModel' + np.str(epochNum) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
