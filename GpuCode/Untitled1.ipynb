{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "WARNING:theano.sandbox.cuda:The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla M60 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os as os\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "#import cv2\n",
    "import h5py\n",
    "import copy\n",
    "from keras.optimizers import SGD\n",
    "from keras import callbacks as cb\n",
    "from keras.layers import Input, merge\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.core import Dropout, Activation\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "import time\n",
    "sys.path.append(os.path.abspath('squeezeNet'))\n",
    "from squeezenet import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/solomond78/Desktop/FishData/binaryScoreMaps\n",
      "fishTypes : LAG\n",
      "number of score maps :  3013\n"
     ]
    }
   ],
   "source": [
    "## this code creates the ground truth images, and the corresponding heatMaps, aquired by hand labelling\n",
    "## of the training data. \n",
    "## the input to my net will be an image of 720x1080x3\n",
    "## the output is a heatMap of 16x27\n",
    "\n",
    "projectPath = '/home/solomond78/Desktop/GIT/FishProject1/fish_keras'\n",
    "dataPath = '/home/solomond78/Desktop/FishData/train'\n",
    "scorePath = os.path.join('/home/solomond78/Desktop/FishData', 'binaryScoreMaps')\n",
    "print scorePath\n",
    "# run through binaryScoreMap folders and count how many are there\n",
    "fishTypes = os.listdir(scorePath)\n",
    "print \"fishTypes : \" + fishTypes[0]\n",
    "numOfImages = 0\n",
    "for fishIdx in np.arange(len(fishTypes)):\n",
    "    fishPath = os.path.join(scorePath, fishTypes[fishIdx])\n",
    "    # filter all non jpg files\\folders\n",
    "    imageNames = [fn for fn in os.listdir(fishPath) if fn.endswith(\"jpg\")]\n",
    "    numOfImages = numOfImages + len(imageNames)\n",
    "    \n",
    "print 'number of score maps : ', numOfImages\n",
    "h_score = 16 #720\n",
    "h_img = 720\n",
    "w_score = 27 #1080\n",
    "w_img = 1080\n",
    "\n",
    "# create an array of all scoreMaps & all images\n",
    "scoreMaps = np.zeros((h_score,w_score,numOfImages))\n",
    "images = np.zeros((numOfImages,3, h_img, w_img), dtype=np.float32)\n",
    "\n",
    "# run through the data, and save all of it within an array\n",
    "counter = 0\n",
    "for fishIdx in np.arange(len(fishTypes)):\n",
    "    fishPath = os.path.join(scorePath, fishTypes[fishIdx])\n",
    "    # filter all non jpg files\\folders\n",
    "    scoreMapNames = [fn for fn in os.listdir(fishPath) if fn.endswith(\"jpg\")]\n",
    "    # run through the images and perform 2 things:\n",
    "    # 1. resize the score images to be of size h_score x w_score\n",
    "    # 2. perform all required data manipulation on the images themselfs..\n",
    "    # save all...\n",
    "    for imageIdx in np.arange(len(scoreMapNames)):\n",
    "        # print the number of image\n",
    "        #print 'image number : ' + np.str(counter) + '/' + np.str(numOfImages)\n",
    "        # everything about the image\n",
    "        imagePath = os.path.join(dataPath, fishTypes[fishIdx], scoreMapNames[imageIdx])\n",
    "        img = misc.imread(imagePath).astype(np.float32)\n",
    "        img = misc.imresize(img, (720, 1080)).astype(np.float32)\n",
    "        #plt.imshow(img)        \n",
    "        aux = copy.copy(img)\n",
    "        img[:, :, 0] = aux[:, :, 2]\n",
    "        img[:, :, 2] = aux[:, :, 0]\n",
    "        # Remove train image mean\n",
    "        img[:, :, 0] -= 104.006\n",
    "        img[:, :, 1] -= 116.669\n",
    "        img[:, :, 2] -= 122.679\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        images[counter,:,:,:] = img\n",
    "        \n",
    "        #everything about the scoreMap\n",
    "        scoreMapPath = os.path.join(fishPath, scoreMapNames[imageIdx])\n",
    "        scoreMap = misc.imread(scoreMapPath, 'L').astype(np.float32)\n",
    "        scoreMap = misc.imresize(scoreMap, (h_score,w_score)).astype(np.bool)\n",
    "        scoreMaps[:,:, counter] = scoreMap\n",
    "        counter += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "np.random.shuffle(images)\n",
    "np.random.seed(1)\n",
    "scoreMaps = np.transpose(scoreMaps, (2,0,1))\n",
    "np.random.shuffle(scoreMaps)\n",
    "scoreMaps = np.transpose(scoreMaps, (1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image as imageClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2711.0\n",
      "(3013, 2, 16, 27)\n"
     ]
    }
   ],
   "source": [
    "print np.floor(0.9*np.size(images,0))\n",
    "print transposedScoreMaps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the array\n",
    "import h5py\n",
    "np.save(\"/home/solomond78/Desktop/FishData/myFile\", images)\n",
    "np.save(\"/home/solomond78/Desktop/FishData/myGroundTruth\", scoreMaps)\n",
    "#images = np.load(\"C:\\\\Users\\\\David\\\\Desktop\\\\Fish\\\\train\\\\myFile.npy\")\n",
    "#scoreMaps = np.load(\"C:\\\\Users\\\\David\\\\Desktop\\\\Fish\\\\train\\\\myGroundTruth.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready to begin training\n"
     ]
    }
   ],
   "source": [
    "# try training the network\n",
    "model = get_squeezenet(2,720,1080, dim_ordering='th')\n",
    "\n",
    "#model.summary()\n",
    "extendedScoreMaps = np.zeros((2,scoreMaps.shape[0],scoreMaps.shape[1],scoreMaps.shape[2]))\n",
    "extendedScoreMaps[0,:,:,:] = 1*np.expand_dims(scoreMaps, axis=0).astype(np.bool)\n",
    "theNumberOne = np.ones((1,1,1,1))\n",
    "extendedScoreMaps[1,:,:,:] = np.abs(extendedScoreMaps[0,:,:,:]-theNumberOne)\n",
    "#print extendedScoreMaps.shape\n",
    "\n",
    "transposedScoreMaps = np.transpose(extendedScoreMaps, (3, 0, 1,2))\n",
    "\n",
    "datagen = imageClass.ImageDataGenerator(\n",
    "            horizontal_flip = True,\n",
    "            vertical_flip = True)\n",
    "print 'ready to begin training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2711 samples, validate on 302 samples\n",
      "Epoch 1/15\n",
      "2700/2711 [============================>.] - ETA: 0s - loss: 0.3111 - acc: 0.8936 - recall: 0.8936Epoch 00000: val_acc improved from -inf to 0.90295, saving model to /home/solomond78/Desktop/FishData/kerasModel/model_weights.00-0.90.h5\n",
      "2711/2711 [==============================] - 187s - loss: 0.3108 - acc: 0.8938 - recall: 0.8938 - val_loss: 0.2553 - val_acc: 0.9030 - val_recall: 0.9030\n",
      "Epoch 2/15\n",
      "2700/2711 [============================>.] - ETA: 0s - loss: 0.2564 - acc: 0.9000 - recall: 0.9000Epoch 00001: val_acc improved from 0.90295 to 0.91235, saving model to /home/solomond78/Desktop/FishData/kerasModel/model_weights.01-0.91.h5\n",
      "2711/2711 [==============================] - 186s - loss: 0.2563 - acc: 0.9001 - recall: 0.9001 - val_loss: 0.2433 - val_acc: 0.9124 - val_recall: 0.9124\n",
      "Epoch 3/15\n",
      "2700/2711 [============================>.] - ETA: 0s - loss: 0.2352 - acc: 0.9062 - recall: 0.9062Epoch 00002: val_acc did not improve\n",
      "2711/2711 [==============================] - 186s - loss: 0.2353 - acc: 0.9061 - recall: 0.9061 - val_loss: 0.2406 - val_acc: 0.9122 - val_recall: 0.9122\n",
      "Epoch 4/15\n",
      "2700/2711 [============================>.] - ETA: 0s - loss: 0.2198 - acc: 0.9122 - recall: 0.9122Epoch 00003: val_acc improved from 0.91235 to 0.92191, saving model to /home/solomond78/Desktop/FishData/kerasModel/model_weights.03-0.92.h5\n",
      "2711/2711 [==============================] - 186s - loss: 0.2199 - acc: 0.9121 - recall: 0.9121 - val_loss: 0.2029 - val_acc: 0.9219 - val_recall: 0.9219\n",
      "Epoch 5/15\n",
      "2700/2711 [============================>.] - ETA: 0s - loss: 0.2095 - acc: 0.9160 - recall: 0.9160Epoch 00004: val_acc did not improve\n",
      "2711/2711 [==============================] - 187s - loss: 0.2095 - acc: 0.9161 - recall: 0.9161 - val_loss: 0.1945 - val_acc: 0.9204 - val_recall: 0.9204\n",
      "Epoch 6/15\n",
      "2700/2711 [============================>.] - ETA: 0s - loss: 0.1947 - acc: 0.9213 - recall: 0.9213Epoch 00005: val_acc improved from 0.92191 to 0.92499, saving model to /home/solomond78/Desktop/FishData/kerasModel/model_weights.05-0.92.h5\n",
      "2711/2711 [==============================] - 186s - loss: 0.1946 - acc: 0.9213 - recall: 0.9213 - val_loss: 0.1840 - val_acc: 0.9250 - val_recall: 0.9250\n",
      "Epoch 7/15\n",
      "2700/2711 [============================>.] - ETA: 0s - loss: 0.1865 - acc: 0.9250 - recall: 0.9250Epoch 00006: val_acc improved from 0.92499 to 0.92815, saving model to /home/solomond78/Desktop/FishData/kerasModel/model_weights.06-0.93.h5\n",
      "2711/2711 [==============================] - 186s - loss: 0.1866 - acc: 0.9249 - recall: 0.9249 - val_loss: 0.1767 - val_acc: 0.9281 - val_recall: 0.9281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2af5da9a10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sgd = SGD(lr=0.003, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#earlyStop = cb.EarlyStopping(monitor='val_acc', min_delta=0.01, patience=2, mode='max')\n",
    "checkPoint = cb.ModelCheckpoint('/home/solomond78/Desktop/FishData/kerasModel/model_weights.{epoch:02d}-{val_acc:.2f}.h5', monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
    "reduce_lr = cb.ReduceLROnPlateau(monitor='acc', factor=0.5, patience=1, min_lr=0.00001)\n",
    "\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='sgd',\n",
    "              metrics=['accuracy', 'recall'])\n",
    "model.load_weights(os.path.abspath('squeezeNet/model/squeezenet_weights_th_dim_ordering_th_kernels.h5'), by_name=True)\n",
    "#model.load_weights('/home/solomond78/Desktop/FishData/kerasModel/thirdModel_epoch0.h5', by_name=True)\n",
    "numOfTraining = np.floor(0.9*np.size(images,0))\n",
    "datagen.fit(images[0:numOfTraining,:,:,:])\n",
    "model.fit(images, transposedScoreMaps, batch_size=18, validation_split=0.1,shuffle=True,\n",
    "                   callbacks=[checkPoint, earlyStop, reduce_lr],\n",
    "                   #validation_data=(images[numOfTraining+1:,:,:,:], transposedScoreMaps[numOfTraining+1:,:,:,:]),\n",
    "                   class_weight=np.array([1.6,0.4]), initial_epoch=7\n",
    "                   verbose=1,  nb_epoch=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2711 samples, validate on 302 samples\n",
      "Epoch 31/40\n",
      "2700/2711 [============================>.] - ETA: 0s - loss: 0.1121 - acc: 0.9542 - recall: 0.9542Epoch 00030: val_acc did not improve\n",
      "2711/2711 [==============================] - 187s - loss: 0.1120 - acc: 0.9542 - recall: 0.9542 - val_loss: 0.1220 - val_acc: 0.9510 - val_recall: 0.9510\n",
      "Epoch 32/40\n",
      "2700/2711 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9544 - recall: 0.9544Epoch 00031: val_acc did not improve\n",
      "2711/2711 [==============================] - 186s - loss: 0.1117 - acc: 0.9544 - recall: 0.9544 - val_loss: 0.1216 - val_acc: 0.9511 - val_recall: 0.9511\n",
      "Epoch 33/40\n",
      "2700/2711 [============================>.] - ETA: 0s - loss: 0.1115 - acc: 0.9542 - recall: 0.9542Epoch 00032: val_acc did not improve\n",
      "2711/2711 [==============================] - 186s - loss: 0.1115 - acc: 0.9542 - recall: 0.9542 - val_loss: 0.1364 - val_acc: 0.9459 - val_recall: 0.9459\n",
      "Epoch 34/40\n",
      "2700/2711 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9554 - recall: 0.9554Epoch 00033: val_acc improved from 0.95132 to 0.95306, saving model to /home/solomond78/Desktop/FishData/kerasModel/model_weights.33-0.95.h5\n",
      "2711/2711 [==============================] - 187s - loss: 0.1091 - acc: 0.9554 - recall: 0.9554 - val_loss: 0.1178 - val_acc: 0.9531 - val_recall: 0.9531\n",
      "Epoch 35/40\n",
      "2700/2711 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9555 - recall: 0.9555Epoch 00034: val_acc did not improve\n",
      "2711/2711 [==============================] - 187s - loss: 0.1085 - acc: 0.9555 - recall: 0.9555 - val_loss: 0.1249 - val_acc: 0.9512 - val_recall: 0.9512\n",
      "Epoch 36/40\n",
      "2700/2711 [============================>.] - ETA: 0s - loss: 0.1066 - acc: 0.9561 - recall: 0.9561Epoch 00035: val_acc did not improve\n",
      "2711/2711 [==============================] - 187s - loss: 0.1067 - acc: 0.9561 - recall: 0.9561 - val_loss: 0.1298 - val_acc: 0.9492 - val_recall: 0.9492\n",
      "Epoch 37/40\n",
      "2700/2711 [============================>.] - ETA: 0s - loss: 0.1055 - acc: 0.9567 - recall: 0.9567Epoch 00036: val_acc did not improve\n",
      "2711/2711 [==============================] - 187s - loss: 0.1054 - acc: 0.9568 - recall: 0.9568 - val_loss: 0.1207 - val_acc: 0.9516 - val_recall: 0.9516\n",
      "Epoch 38/40\n",
      "2700/2711 [============================>.] - ETA: 0s - loss: 0.1055 - acc: 0.9568 - recall: 0.9568Epoch 00037: val_acc did not improve\n",
      "2711/2711 [==============================] - 187s - loss: 0.1057 - acc: 0.9567 - recall: 0.9567 - val_loss: 0.1194 - val_acc: 0.9528 - val_recall: 0.9528\n",
      "Epoch 39/40\n",
      "2700/2711 [============================>.] - ETA: 0s - loss: 0.1045 - acc: 0.9572 - recall: 0.9572Epoch 00038: val_acc did not improve\n",
      "2711/2711 [==============================] - 187s - loss: 0.1045 - acc: 0.9571 - recall: 0.9571 - val_loss: 0.1183 - val_acc: 0.9528 - val_recall: 0.9528\n",
      "Epoch 40/40\n",
      "2700/2711 [============================>.] - ETA: 0s - loss: 0.1038 - acc: 0.9573 - recall: 0.9573Epoch 00039: val_acc improved from 0.95306 to 0.95508, saving model to /home/solomond78/Desktop/FishData/kerasModel/model_weights.39-0.96.h5\n",
      "2711/2711 [==============================] - 187s - loss: 0.1038 - acc: 0.9573 - recall: 0.9573 - val_loss: 0.1144 - val_acc: 0.9551 - val_recall: 0.9551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2b03830d50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(images, transposedScoreMaps, batch_size=18, validation_split=0.1,shuffle=True,\n",
    "                   callbacks=[checkPoint, reduce_lr],\n",
    "                   #validation_data=(images[numOfTraining+1:,:,:,:], transposedScoreMaps[numOfTraining+1:,:,:,:]),\n",
    "                   class_weight=np.array([1.6,0.4]), initial_epoch=30,\n",
    "                   verbose=1,  nb_epoch=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "extendedScoreMaps = np.zeros((2,scoreMaps.shape[0],scoreMaps.shape[1],scoreMaps.shape[2]))\n",
    "extendedScoreMaps[0,:,:,:] = 1*np.expand_dims(scoreMaps, axis=0).astype(np.bool)\n",
    "#extendedScoreMaps = 1*extendedScoreMaps.astype(np.bool)\n",
    "theNumberOne = np.ones((1,1,1,1))\n",
    "extendedScoreMaps[1,:,:,:] = np.abs(extendedScoreMaps[0,:,:,:]-theNumberOne)\n",
    "print extendedScoreMaps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         ..., \n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         ..., \n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         ..., \n",
       "         [-1., -1., -1., ..., -1., -1.,  0.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.]],\n",
       "\n",
       "        ..., \n",
       "        [[-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         ..., \n",
       "         [-1., -1., -1., ...,  0., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         ..., \n",
       "         [-1., -1., -1., ...,  0., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         ..., \n",
       "         [-1., -1., -1., ...,  0., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.]]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(images[0:numOfTraining,:,:,:], transposedScoreMaps[0:numOfTraining,:,:,:], batch_size=18),\n",
    "                   callbacks=[checkPoint, earlyStop, reduce_lr],\n",
    "                   #validation_data=(images[numOfTraining+1:,:,:,:], transposedScoreMaps[numOfTraining+1:,:,:,:]),\n",
    "                   class_weight=np.array([1.6,0.4]),\n",
    "                   verbose=1, samples_per_epoch=np.int(numOfTraining), nb_epoch=15)\n",
    "extendedScoreMaps.shape\n",
    "theNumberOne = np.ones((1,1,1,1))\n",
    "theNumberOne.shape\n",
    "extendedScoreMaps-theNumberOne\n",
    "for epochNum in np.arange(10):\n",
    "    model.fit(x=images, y=transposedScoreMaps, batch_size=18, nb_epoch=epochNum+1, verbose=1, callbacks=None, validation_split=0.1, shuffle=True, class_weight=np.array([1.5,0.5]), sample_weight=None, initial_epoch=epochNum)\n",
    "    model.save('/home/solomond78/Desktop/FishData/kerasModel/thirdModel_epoch' + np.str(epochNum) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
